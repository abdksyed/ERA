{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "q-ua0LxAODfm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJptKBxALl-u",
        "outputId": "b5fa5ec5-8ced-4ca6-aa02-10e8a8d26443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Owi1LBNY8L",
        "outputId": "358cd4ab-f62a-4770-9c4c-1d88bd4587e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size for training and testing\n",
        "batch_size = 128\n",
        "\n",
        "# Training DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,  # MNIST training dataset\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))  # Normalize the tensor\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True  # Set batch size\n",
        "                                        # Shuffle Data during each call.\n",
        ")\n",
        "\n",
        "# Testing DataLoader\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False,  # MNIST testing dataset\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))  # Normalize the tensor\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True  # Set batch size and shuffle the data\n",
        ")"
      ],
      "metadata": {
        "id": "EQZaZRGcNLtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Notes on our naive model\n",
        "\n",
        "We are going to write a network based on what we have learnt so far. \n",
        "\n",
        "The size of the input image is 28x28x1. We are going to add as many layers as required to reach RF = 32 \"atleast\". "
      ],
      "metadata": {
        "id": "r3gEjf-xMb-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "    # r_in: , n_in: , j_in: , s: , r_out: , n_out: , j_out:\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    x = F.relu(self.conv7(x)) \n",
        "    x = x.view(-1, 10)\n",
        "    return F.log_softmax(x)\n"
      ],
      "metadata": {
        "id": "yPqaEOJOOC_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer"
      ],
      "metadata": {
        "id": "q-ua0LxAODfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstDNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FirstDNN, self).__init__()\n",
        "\n",
        "    # r_in:1, n_in:28, j_in:1, s:1, r_out:3, n_out:28, j_out:1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "\n",
        "    # r_in:3, n_in:28, j_in:1, s:1, r_out5: , n_out:28, j_out:1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "    # r_in:5, n_in:28, j_in:1, s:2, r_out:6, n_out:14, j_out:2\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # r_in:6, n_in:14, j_in:2, s:1, r_out:10, n_out:14, j_out:2\n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "    # r_in:10, n_in:14, j_in:2, s:1, r_out:14, n_out14: , j_out:2\n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "\n",
        "    # r_in:14, n_in:14, j_in:2, s:2, r_out:16, n_out:7, j_out:4\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # r_in:16, n_in:7, j_in:4, s:1, r_out:24, n_out:5, j_out:4\n",
        "    self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "\n",
        "    # r_in:24, n_in:5, j_in:4, s:1, r_out:32, n_out:3, j_out:4\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "\n",
        "    # r_in:32, n_in:3, j_in:4, s:1, r_out:40, n_out:1, j_out:4\n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "    # Correct Values\n",
        "    # https://user-images.githubusercontent.com/498461/238034116-7db4cec0-7738-42df-8b67-afa971428d39.png\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "    x = self.conv7(x) # Correct answer is to remove the ReLU from here\n",
        "    x = x.view(-1, 10)\n",
        "    return F.log_softmax(x, dim=-1)\n"
      ],
      "metadata": {
        "id": "Sir2LmSVLr_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "EIhbs76TOGva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FirstDNN().to(device)"
      ],
      "metadata": {
        "id": "sxICO4TTNt2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M__MtFIYNwXa",
        "outputId": "fa1c94f6-8a08-44e5-a722-0378210d1149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "    pbar = tqdm(train_loader)  # Initialize tqdm with the train_loader\n",
        "    for batch_idx, (data, target) in enumerate(pbar):  # Iterate over the batches\n",
        "        data, target = data.to(device), target.to(device)  # Move data to device\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        output = model(data)  # Forward pass: compute model output\n",
        "        # output: Softmax'd Output, target: Ground Truth Logits \n",
        "        loss = F.nll_loss(output, target)  # Calculate the NLL loss\n",
        "\n",
        "        loss.backward()  # Backpropagation: compute gradients\n",
        "        optimizer.step()  # Update model parameters using optimizer\n",
        "\n",
        "        # Update the progress bar description with current loss and batch index\n",
        "        pbar.set_description(desc=f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "g_vlC-bdNzo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0FYVWkGOFBS",
        "outputId": "15dfea72-f841-4093-d9b8-46147aa9bcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.06345539540052414 batch_id=468: 100%|██████████| 469/469 [00:30<00:00, 15.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0572, Accuracy: 9816/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Epoch 2"
      ],
      "metadata": {
        "id": "v3J3aLe7MT_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(2, 3):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "reIBU667OG_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1452c930-499c-4512-e8e3-057456253fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.01634179800748825 batch_id=468: 100%|██████████| 469/469 [00:31<00:00, 14.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0399, Accuracy: 9856/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}